{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d207b762",
   "metadata": {},
   "source": [
    "# Cafe refresh-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cf0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   lot folks twitter already spoke good terminal ...  Positive\n",
      "1   bangalore airport ninchi baitaki raagane micro...   Neutral\n",
      "2   early morning flight catch one shud go bangalo...  Positive\n",
      "3   check mitti cafe around bangalore airport purp...   Neutral\n",
      "4   part history making today bangalore airport be...   Neutral\n",
      "..                                                ...       ...\n",
      "64  Bangalore's famous filter coffee best way wake...  Positive\n",
      "65  Exploring airport's bookshop. cup chamomile te...  Positive\n",
      "66  always get cup buttermilk I'm airport. refresh...   Neutral\n",
      "67  Late-night craving. airport's 24/7 coffee shop...   Neutral\n",
      "68  Sunday breakfast airport cafe view. great way ...  Positive\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\cafe refresh1.csv\"\n",
    "output_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\cafe refresh1.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cedca75",
   "metadata": {},
   "source": [
    "# Food refresh-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d9258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   came sat near picked remnants pongal consumed ...  Positive\n",
      "1   blrairport bangalore airport outside food cour...  Positive\n",
      "2   soon step bangalore airport building two thing...  Negative\n",
      "3   kidding bangalore airport food court like down...  Positive\n",
      "4   traveled bangalore airport mysore finding petr...  Negative\n",
      "5   bangalore airport seem forgotten suppose run a...  Negative\n",
      "6   til karnataka style restaurant t3 food court d...   Neutral\n",
      "7   bangalore airport food court immersed book did...   Neutral\n",
      "8   came picked remnants pongal mind seeing sparro...  Positive\n",
      "9   huh bangalore airport pretty comprehensive foo...  Positive\n",
      "10  time 2011 precise sparrows could found inside ...   Neutral\n",
      "11  fact last sparrows saw close departure termina...  Positive\n",
      "12  getting better opinion bangalore airport takes...  Positive\n",
      "13  thank staying connected coupon applicable case...  Positive\n",
      "14  saffrontrail livefromalounge bangalore airport...  Positive\n",
      "15  bangalore airport sparrows hopping around food...   Neutral\n",
      "16  airlines charge 500 bucks crappy food bangalor...  Negative\n",
      "17      try food court bangalore airport costly tasty  Negative\n",
      "18  biggest challenge bangalore airport finding se...  Positive\n",
      "19                 birds bangalore airport food court   Neutral\n",
      "20              remember bangalore airport food court   Neutral\n",
      "21  disturbed sparrows going extinct urban areas v...  Negative\n",
      "22  india funnily though see lots sparrows bangalo...  Negative\n",
      "23  taste india bangalore airport filled like mall...  Positive\n",
      "24         many sparrows bangalore airport food court   Neutral\n",
      "25        bangalore airport food court sucks big time  Negative\n",
      "26  sparrow invasion bangalore airport food court ...   Neutral\n",
      "27  sparrows flying around food court bangalore ai...   Neutral\n",
      "28  well lots sparrows inside bangalore airport pi...  Positive\n",
      "29  best company u could get bangalore airport foo...  Positive\n",
      "30  species wings place bangalore airport sparrows...   Neutral\n",
      "31  thick dense fog flight operations go haywire b...   Neutral\n",
      "32  bangalore airport using one self ordering kios...   Neutral\n",
      "33  dangerous close airport rt sachinkalbag sparro...  Negative\n",
      "34  young prozpekt lol n half bangalore airport fo...  Positive\n",
      "35  Avoid sugary fried foods Cut soft drinks .Made...  Positive\n",
      "36  smooth Landing Woman Pilots Indigo 6E 229 Chen...  Positive\n",
      "37  Bangalore Aviation . person screaming water.Th...  Positive\n",
      "38  Checked street food-style stalls airport. feel...  Positive\n",
      "39  Time dessert. gelato Bangalore Airport sweet t...  Positive\n",
      "40  Love BLR Airport wide selection fresh fruit ju...  Positive\n",
      "41               Tried local mango lassi. refreshing.   Neutral\n",
      "42  miss chaat stall Bangalore Airport. flavor exp...  Negative\n",
      "43  Stumbled upon local bakery airport. pastries h...  Positive\n",
      "44  Waiting connecting flight plate crispy pakoras...  Positive\n",
      "45  can't resist aroma freshly baked bread airport...   Neutral\n",
      "46  food court BLR Airport like mini food festival...  Positive\n",
      "47  Bangalore Airport, must try vada pav. local fa...  Positive\n",
      "48  Grabbing pizza slice go. airport's pizzeria ma...  Positive\n",
      "49  Garden City, locals do. Savored coconut water ...   Neutral\n",
      "50  Airport food courts come long way. Bangalore A...  Positive\n",
      "51  Found cute little bakery picked fresh macarons...  Positive\n",
      "52  Grabbing quick bite airport food truck. kebabs...   Neutral\n",
      "53  Indian street food best.Tried pani puri BLR Ai...  Positive\n",
      "54  Stopping bakery muffin. treats perfect mid-fli...  Positive\n",
      "55  Staying healthy track fruit salad airport's ju...  Positive\n",
      "56  Browsing duty-free shops creamy milkshake hand...  Positive\n",
      "57   Tried airport's tandoori platter. flavors world.   Neutral\n",
      "58  Grabbing smoothie beat heat. airport's smoothi...   Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\food refresh1.csv\"\n",
    "output_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\food refresh1.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512148c3",
   "metadata": {},
   "source": [
    "# Restaurant refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ef9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   don' call india land thalis lightly thali rest...   Neutral\n",
      "1   landed bangalore airport pleasantly surprised ...  Positive\n",
      "2   want open vegan restaurant bangalore airport n...  Positive\n",
      "3   blr airport bbmp comm surprising see restauran...  Negative\n",
      "4   even though bangalore airport may worse restau...  Positive\n",
      "..                                                ...       ...\n",
      "94  quick dosa flight.Yes, please.The airport's do...  Positive\n",
      "95  airport's breakfast buffet delightful surprise...  Positive\n",
      "96  healthy filling Mediterranean salad lunch. Air...  Positive\n",
      "97  Stuck transit.No worries. airport's spa serves...  Positive\n",
      "98  Bangalore Airport's food scene diverse. Tried ...   Neutral\n",
      "\n",
      "[99 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\restarunt refresh1.csv\"\n",
    "output_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\restarunt refresh1.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b50e3",
   "metadata": {},
   "source": [
    "# cafe Refresh-1LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75027e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\cafe refresh1.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\cafe refresh1LDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba214344",
   "metadata": {},
   "source": [
    "# Food refresh-1LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c2f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\food refresh1.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\food refresh1LDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09d031",
   "metadata": {},
   "source": [
    "# Restaurant refresh-1LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1190a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\restarunt refresh1.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Food & Beverages\\\\restarunt refresh1LDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d2b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
