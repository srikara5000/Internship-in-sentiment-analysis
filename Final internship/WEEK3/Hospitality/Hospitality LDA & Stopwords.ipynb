{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255b80a1",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db402f",
   "metadata": {},
   "source": [
    "# Check-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d0693bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             full_text sentiment\n",
      "0    bangalore airport best airport ive entire indi...  Positive\n",
      "1    yatra supposed reduce time apparently right ba...  Positive\n",
      "2    entered 2 hours departure thats 120 minutes to...  Positive\n",
      "3    issue checking online prajawal bangera bangalo...  Positive\n",
      "4    house bangalore parents house salem reach 3 hr...  Positive\n",
      "..                                                 ...       ...\n",
      "96   today experienced future travel experience ban...  Positive\n",
      "97   good experience flights bad experience airvist...  Negative\n",
      "98   Took Air India Bangalore Mumbai Flight delayed...  Negative\n",
      "99   Kudos guy Happened see one incident Bangalore ...   Neutral\n",
      "100  flight Bangalore airindia AI176 seemed like gr...  Positive\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\check-in.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\check-in.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd680e",
   "metadata": {},
   "source": [
    "# Hospitality-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75479d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   oh please bangalore airport never seen hospita...  Positive\n",
      "1   superb hospitality exceptional service alfia n...  Positive\n",
      "2   always pleasure visit lounge bangalore airport...  Positive\n",
      "3   harassed bangalore airport today group staff 1...  Negative\n",
      "4   unmatched hospitality grace thank taj bangalor...  Positive\n",
      "5   sure back soon must commend excellent lounge b...  Positive\n",
      "6   waiting airport fly kolkata beautiful airport ...  Positive\n",
      "7   discovered swissness working bangalore airport...  Positive\n",
      "8   hotels near bangalore airport internation airp...  Positive\n",
      "9   seamless travel exceptional comfort experience...  Positive\n",
      "10  thank kempegowda bangalore airport hospitality...  Positive\n",
      "11  vistara one manager whole bangalore airport do...  Negative\n",
      "12  blr lounge bangalore airport waiting board fli...  Positive\n",
      "13  travelled bus route 8 bangalore airport hospit...  Positive\n",
      "14  pathetic hospitality bangalore airport fight d...  Negative\n",
      "15  domestic lounge bangalore airport cosy place r...  Positive\n",
      "16  sharwin thank good hospitality service never g...  Positive\n",
      "17  conveniently located kempegowda international ...  Positive\n",
      "18  bangalore launch may times never disappointed ...  Positive\n",
      "19  lounge experience good bangalore airport hospi...  Positive\n",
      "20  really nice experience bangalore airport loung...  Positive\n",
      "21  experience airport staff pleasant overwhelmed ...  Positive\n",
      "22  indigo best always 6e 6sigma bangalore airport...  Positive\n",
      "23  taj bad eg one near bangalore airport se asian...  Negative\n",
      "24  breaking news thanks govt citizen india provid...  Positive\n",
      "25  front desk girl power margret bangalore airpor...  Positive\n",
      "26  group dealing energy resources airports transp...  Negative\n",
      "27  thank meet assist hospitality bangalore airpor...  Positive\n",
      "28  one direct partnered plaza premium group ensur...  Positive\n",
      "29  would like thanks mr manjunath team wonderful ...  Positive\n",
      "30  today traveling bangalore madurai enjoyed serv...  Positive\n",
      "31  bangalore airport lounge ambience hospitality ...  Positive\n",
      "32  short sweet story bangalore airport bored jour...  Positive\n",
      "33  transfer flight wait long bangalore airport mu...  Positive\n",
      "34  shitty experience disgusting attitude personne...  Negative\n",
      "35  worst experience travelling bangalore airport ...  Negative\n",
      "36  thank spandana wonderful hospitality service w...  Positive\n",
      "37  ridiculous hospitality Bangalore Mumbai indigo...  Negative\n",
      "38  Worst ever experience terms hospitality humani...  Negative\n",
      "39  surprised see hospitality India IndiGo company...   Neutral\n",
      "40  Assured Bengaluru Airport transfers class lead...  Positive\n",
      "41  Enjoying Spicejet hospitality broken armrest a...  Positive\n",
      "42  staff airport local auto rickshaw drivers mass...  Positive\n",
      "43  Hospitality Conrad Bangalore terrible best ban...  Positive\n",
      "44  Thank wonderful hospitality service beautiful ...  Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_1.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_1.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9da04",
   "metadata": {},
   "source": [
    "# Hospitality-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b65a3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   oh please bangalore airport never seen hospita...  Positive\n",
      "1   harassed bangalore airport today group staff 1...  Negative\n",
      "2   seamless travel exceptional comfort experience...  Positive\n",
      "3   superb hospitality exceptional service alfia n...  Positive\n",
      "4   hotels near bangalore airport internation airp...  Positive\n",
      "5   taj bad eg one near bangalore airport se asian...  Negative\n",
      "6   really nice experience bangalore airport loung...  Positive\n",
      "7   always pleasure visit lounge bangalore airport...  Positive\n",
      "8   experience airport staff pleasant overwhelmed ...  Positive\n",
      "9   bangalore airport lounge ambience hospitality ...  Positive\n",
      "10  lounge experience good bangalore airport hospi...  Positive\n",
      "11  worst experience travelling bangalore airport ...  Negative\n",
      "12  one direct partnered plaza premium group ensur...  Positive\n",
      "13  bangalore launch may times never disappointed ...  Positive\n",
      "14  indigo best always 6e 6sigma bangalore airport...  Positive\n",
      "15  today traveling bangalore madurai enjoyed serv...  Positive\n",
      "16  would like thanks mr manjunath team wonderful ...  Positive\n",
      "17  group dealing energy resources airports transp...  Negative\n",
      "18  short sweet story bangalore airport bored jour...  Positive\n",
      "19  domestic lounge bangalore airport cosy place r...  Positive\n",
      "20  thank kempegowda bangalore airport hospitality...  Positive\n",
      "21  unmatched hospitality grace thank taj bangalor...  Positive\n",
      "22  blr lounge bangalore airport waiting board fli...  Positive\n",
      "23  transfer flight wait long bangalore airport mu...  Positive\n",
      "24  discovered swissness working bangalore airport...  Positive\n",
      "25  vistara one manager whole bangalore airport do...  Negative\n",
      "26  sharwin thank good hospitality service never g...  Positive\n",
      "27  shitty experience disgusting attitude personne...  Negative\n",
      "28  thank meet amp assist hospitality bangalore ai...  Positive\n",
      "29  front desk girl power margret bangalore airpor...  Positive\n",
      "30  thank spandana wonderful hospitality service w...  Positive\n",
      "31  thanks govt citizen india providing high profi...  Positive\n",
      "32  travelled bus route 8 bangalore airport hospit...  Positive\n",
      "33  pathetic hospitality bangalore airport fight d...  Negative\n",
      "34  sure back soon must commend excellent lounge b...  Positive\n",
      "35  waiting fly kolkata beautiful airport enjoying...  Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_2.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_2.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae708f",
   "metadata": {},
   "source": [
    "# Lounge refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43929a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   frustrated upset mastercard elite cards restri...  Negative\n",
      "1   bangalore airport lounge credit card access go...  Positive\n",
      "2   blrairport 080 lounge bangalore airport fantas...  Positive\n",
      "3   used bangalore airport excellent experience to...  Positive\n",
      "4   also found bangalore airport t1 lounge mataji ...  Positive\n",
      "..                                                ...       ...\n",
      "74  Jun 9 Nice Design overall T2 Airport looks lik...   Neutral\n",
      "75  Luxury Business Hotel Hotels near Bangalore In...   Neutral\n",
      "76  Hotel Golden Evana provides hotel close Bangal...  Positive\n",
      "77  Red Key budget friendly 2 star hotel Bangalore...  Positive\n",
      "78  Taj Bangalore mere walk away Kempe Gowda Inter...  Positive\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\lounge refresh.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\lounge refresh.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1361e94",
   "metadata": {},
   "source": [
    "# Waiting refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74731d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   airline pain waiting 30 min baggage drop banga...  Negative\n",
      "1   remember sitting bangalore airport night trave...   Neutral\n",
      "2             unstablemaria waiting bangalore airport   Neutral\n",
      "3   much bangalore airport t2 wonderful inside out...  Negative\n",
      "4   looks like waiting area first floor bangalore ...  Positive\n",
      "..                                                ...       ...\n",
      "82  airindiain landing bangalore airport waiting b...  Positive\n",
      "83  literally spent time precise 1 5 hours waiting...   Neutral\n",
      "84  chaipoint_cares pls take care service quality ...  Positive\n",
      "85  people waiting taxis new bangalore airport som...  Positive\n",
      "86  hey uber long queue bangalore airport t2 drive...  Positive\n",
      "\n",
      "[87 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting referesh.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting referesh.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab3997",
   "metadata": {},
   "source": [
    "# Waiting area refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0f7a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            full_text sentiment\n",
      "0   looks like waiting area first floor bangalore ...  Positive\n",
      "1   bangalore airport waiting area seat trash lear...  Positive\n",
      "2   waited 40 minutes uber zone cab bangalore airp...  Negative\n",
      "3   blrairport officejmsc india jmscindia dgcaindi...  Positive\n",
      "4   mediacrooks rajnathsingh jayantsinha narendram...   Neutral\n",
      "5   blrairport today travelling bangalore airport ...  Positive\n",
      "6   bangalore airport going jaipur kempegowda inte...   Neutral\n",
      "7   crows inside bangalore airport crowing away ne...   Neutral\n",
      "8   hot sizzling erotic girl sitting front waiting...   Neutral\n",
      "9   cutemoments child sitting luggage trolley wait...   Neutral\n",
      "10  atleast 20 passengers waiting taxi absolutely ...  Negative\n",
      "11  remember sitting bangalore airport night trave...   Neutral\n",
      "12  bangalore airport nicepic niceplace kempegowda...   Neutral\n",
      "13  birds bangalore airport waiting area garden ci...   Neutral\n",
      "14  guy sitting next solved germany economic reces...  Positive\n",
      "15  bangalore airport delhi kempegowda internation...   Neutral\n",
      "16  bangalore airport small domestic international...  Positive\n",
      "17  bangalore airport large plush domestic transfe...  Negative\n",
      "18  time bangalore airport good try visiting groun...  Positive\n",
      "19  jetairways waiting half hour baggage services ...   Neutral\n",
      "20  puro gusto coffee shop waiting area bangalore ...  Positive\n",
      "21  foreigners waiting bangalore airport cab picku...   Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91831\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  # Download the stopwords if you haven't already\n",
    "\n",
    "# Define a function to remove stopwords from a tweet\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = tweet.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting_area refresh.csv\"\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting_area refresh.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_file,encoding='ISO-8859-1')\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df['full_text'] = df['full_text'].apply(remove_stopwords)\n",
    "print(df)\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6859296",
   "metadata": {},
   "source": [
    "# check In LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bcbf9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\check-in.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\check-inLDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395af15",
   "metadata": {},
   "source": [
    "# Hospitality-1 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87f1ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_1.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_1LDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48640b39",
   "metadata": {},
   "source": [
    "# Hospitality-2LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "380efa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_2.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\hospitality_2LDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22445b",
   "metadata": {},
   "source": [
    "# Lounge refreshLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54914f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\lounge refresh.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\lounge refreshLDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef282d4",
   "metadata": {},
   "source": [
    "# Waiting refreshLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "902055a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting referesh.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting refereshLDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efb3e3",
   "metadata": {},
   "source": [
    "# Waiting area refreshLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05edcd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the input CSV file\n",
    "input_csv_file =\"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting_area refresh.csv\"\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Tokenize the tweets and create a dictionary and corpus\n",
    "texts = [tweet.split() for tweet in df['full_text']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5  # You can adjust this number\n",
    "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "# Calculate word frequency by topic\n",
    "word_frequency_by_topic = {topic_id: Counter() for topic_id in range(num_topics)}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tweet = row['full_text']\n",
    "    tweet_bow = dictionary.doc2bow(tweet.split())\n",
    "    topics = lda_model[tweet_bow]\n",
    "    for topic, probability in topics:\n",
    "        word_frequency_by_topic[topic].update(tweet.split())\n",
    "\n",
    "# Store word frequencies in a new CSV file\n",
    "output_csv_file = \"D:\\\\Internship Progress\\\\WEEK3\\\\Hospitality\\\\waiting_area refreshLDA.csv\"\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Topic', 'Word', 'Frequency'])\n",
    "\n",
    "    for topic_id, word_frequency in word_frequency_by_topic.items():\n",
    "        for word, frequency in word_frequency.items():\n",
    "            csv_writer.writerow([topic_id, word, frequency])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a4eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
